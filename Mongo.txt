Non Relational datastore for JSON docs.
Its Schemaless.

db.help() gives all commands.
db.stats() provides various stats

Creating and Finding Docs
> db.things.save({a:1,b:2,c:3})
> db.things.find()
{ "_id" : ObjectId("541aecb39231b8f7823214ed"), "a" : 1, "b" : 2, "c" : 3 }
> db.things.save({a:1,b:2,c:3,d:100})
> db.things.find()
> db.things.find({d:100})
{ "_id" : ObjectId("541aecc89231b8f7823214ee"), "a" : 1, "b" : 2, "c" : 3, "d" : 100 }
>

Subdocuments:
> db.things.save({a:1,fruits:['apple','baan']})
> db.things.save()
> db.things.find()
{ "_id" : ObjectId("541aecb39231b8f7823214ed"), "a" : 1, "b" : 2, "c" : 3 }
{ "_id" : ObjectId("541aecc89231b8f7823214ee"), "a" : 1, "b" : 2, "c" : 3, "d" : 100 }
{ "_id" : ObjectId("541aee1adadcbf2334b38e5e"), "a" : 1, "fruits" : [  "apple",  "baan" ] }
> db.things.save({name:'Simon',address:{street:'Indal',pin:590010}})
> db.things.find()
{ "_id" : ObjectId("541aecb39231b8f7823214ed"), "a" : 1, "b" : 2, "c" : 3 }
{ "_id" : ObjectId("541aecc89231b8f7823214ee"), "a" : 1, "b" : 2, "c" : 3, "d" : 100 }
{ "_id" : ObjectId("541aee1adadcbf2334b38e5e"), "a" : 1, "fruits" : [  "apple",  "baan" ] }
{ "_id" : ObjectId("541aee5cdadcbf2334b38e5f"), "name" : "Simon", "address" : { "street" : "Indal", "pin" : 590010 } }
>

Prettify:
> db.things.find().pretty()
{ "_id" : ObjectId("541aecb39231b8f7823214ed"), "a" : 1, "b" : 2, "c" : 3 }
{
	"_id" : ObjectId("541aecc89231b8f7823214ee"),
	"a" : 1,
	"b" : 2,
	"c" : 3,
	"d" : 100
}
{
	"_id" : ObjectId("541aee1adadcbf2334b38e5e"),
	"a" : 1,
	"fruits" : [
		"apple",
		"baan"
	]
}
{
	"_id" : ObjectId("541aee5cdadcbf2334b38e5f"),
	"name" : "Simon",
	"address" : {
		"street" : "Indal",
		"pin" : 590010
	}
}



Sample Program:

import pymongo

from pymongo import Connection
conn = Connection('localhost',27017)
db = conn.test
things = db.things
item = things.find()
for i in item:
	try:
		print i['a']
	except KeyError:
		pass	



> j = db.things.findOne({fruits:'apple'})
{
	"_id" : ObjectId("541aee1adadcbf2334b38e5e"),
	"a" : 1,
	"fruits" : [
		"apple",
		"baan"
	]
}
> j
{
	"_id" : ObjectId("541aee1adadcbf2334b38e5e"),
	"a" : 1,
	"fruits" : [l
		"apple",
		"baan"
	]
}
> j.b=2
2


 db.things.find()
{ "_id" : ObjectId("541aecb39231b8f7823214ed"), "a" : 1, "b" : 2, "c" : 3 }
{ "_id" : ObjectId("541aecc89231b8f7823214ee"), "a" : 1, "b" : 2, "c" : 3, "d" : 100 }
{ "_id" : ObjectId("541aee5cdadcbf2334b38e5f"), "name" : "Simon", "address" : { "street" : "Indal", "pin" : 590010 } }
{ "_id" : ObjectId("541aee1adadcbf2334b38e5e"), "a" : 1, "fruits" : [  "apple",  "baan" ], "b" : 2 }



From within pymongo db.test.insert({}) used to insert data.

Mongo dump and mongo restore used to load and dump data in bulk.
mongorestore command used to restore.

Drop:
> use test_database
switched to db test_database
> db.dropDatabase()
{ "dropped" : "test_database", "ok" : 1 }

Create Collection:
>db.createCollection("mycol", { capped : true, autoIndexID : true, size : 6142800, max : 10000 } )
{ "ok" : 1 

cap the collection at <<size>> bytes or max 10000 docs


Drop Collections:
>db.mycollection.drop()


CRUD Operations:

Insert:
> doc = {name:"Simon",lname:"Hanchinamani",profession:"Hacker"}
{ "name" : "Simon", "lname" : "Hanchinamani", "profession" : "Hacker" }
> db.people.insert(doc)
> db.people.find()
{ "_id" : ObjectId("541f215a2e045cee43b63854"), "name" : "Simon", "lname" : "Hanchinamani", "profession" : "Hacker" }
_id is 12 bytes hexadecimal number unique for every document in a collection. 12 bytes are divided as follows:
_id: ObjectId(4 bytes timestamp, 3 bytes machine id, 2 bytes process id, 3 bytes incrementer

To insert the document you can use db.post.save(document) also. If you don't specify _id in the document then save() method will work same as insert() method. If you specify _id then it will replace whole data of document containing _id as specified in save() method.



Find One and Find
> db.people.findOne({lname:"Hanchinamani"})
First arg simulates the where clause and Second arguement controls the attributes returned from the collections
> db.people.findOne({lname:"Hanchinamani"},{name:true,_id:false})
{ "name" : "Simon" }

> db.scores.find({student:1,type:'essay'},{scores:true})
{ "_id" : ObjectId("52fbc7f1165d12ae4e62d1fa"), "scores" : 72 }

GT, LT etc.
> db.scores.find({student:{$lt:3},type:'essay'})
{ "_id" : ObjectId("52fbc7f1165d12ae4e62d1f7"), "student" : 0, "type" : "essay", "scores" : 46 }
{ "_id" : ObjectId("52fbc7f1165d12ae4e62d1fa"), "student" : 1, "type" : "essay", "scores" : 72 }
{ "_id" : ObjectId("52fbc7f1165d12ae4e62d1fd"), "student" : 2, "type" : "essay", "scores" : 32 }

> db.scores.find({student:{$lt:3,$gte:1},type:'essay'})
{ "_id" : ObjectId("52fbc7f1165d12ae4e62d1fa"), "student" : 1, "type" : "essay", "scores" : 72 }
{ "_id" : ObjectId("52fbc7f1165d12ae4e62d1fd"), "student" : 2, "type" : "essay", "scores" : 32 }


AND :
db.mycol.find({"by":"tutorials point","title": "MongoDB Overview"})

OR:
db.mycol.find({$or:[{"by":"tutorials point"},{"title": "MongoDB Overview"}]}

*Update:
MongoDB's update() and save() methods are used to update document into a collection. The update() method update values in the existing document while the save() method replaces the existing document with the document passed in save() method.

>db.mycol.update({'title':'MongoDB Overview'},{$set:{'title':'New MongoDB Tutorial'}})

By default mongodb will update only single document, to update multiple you need to set a paramter 'multi' to true.
>db.mycol.update({'title':'MongoDB Overview'},{$set:{'title':'New MongoDB Tutorial'}},{multi:true})

*Remove:
>db.mycol.remove({'title':'MongoDB Overview'})

If you don't specify deletion criteria, then mongodb will delete whole documents from the collection. This is equivalent of SQL's truncate command.
>db.mycol.remove()


*All:
db.people.find({name:{$all:['simon','simons']}})
*In
db.people.find({name:{$in:['simon','simons']}})


Dot Notation can be used for embedded nested documents , here address is nested within user documet.
db.people.find({'user.address':'indal'})


*Update:
db.people.update({name:'simon'},{'name':'Simon'}) # This remove all other fields if it exists other than name.

*To prevent above we can do below:
db.people.update({name:'simon'},{$set:{'name':'Simon'}})
db.people.update({name:'simon'},{$unset:{'name':'Simon'}}) # this will remove this field from the doc

for doc such as {_id:1,a:[1,2,3,4]} to add elements to a filed we do below
db.people.update({_id:1},{$push:{a:5}})  #similaryly use pop or pushAll to add multiple elemets simultaneously, pull and pullALL removes specified values


*Upserts:
Adds a docuemtn if it doesnt already exist. for ex:
db.people.update({name:Simon},{age:30},{upsert=1}) # THis adds a docuemtn if a docusntme with name Simon doesnt already exist.

*multi: By default mongo update affects only one document even if the criteria amthces multiple docs. use multi to change all matching docs.
db.people.update({},{age:30},{multi=1})


*db.runCommand({getLastError:1}) # Gives the status of the last command executed




*query_plan : the procedure of choosing a fastest index


*Profieling; db.system.profile.find({millis:{$gt:10000}})

*LIMIT and SKIP*
Following example will display only 2 documents while quering the document.
> db.people.find({},{name:1,_id:0}).limit(3)
{ "name" : "Simon" }
{ "name" : "Pree1" }
{ "name" : "Alice" }
> db.people.find({},{name:1,_id:0}).limit(3).skip(1)
{ "name" : "Pree1" }
{ "name" : "Alice" }
{ "name" : "Bob" }




*SORT*
Following example will display the documents sorted by title in descending order.

>db.mycol.find({},{"title":1,_id:0}).sort({"title":-1})
{"title":"Tutorials Point Overview"}
{"title":"NoSQL Overview"}
{"title":"MongoDB Overview"}







*INDEX*
>db.mycol.ensureIndex({"title":1})
In ensureIndex() method you can pass multiple fields, to create index on multiple fields.
>db.mycol.ensureIndex({"title":1,"description":-1})

few Options for ensureIndex
unique	: Boolean	Creates a unique index so that the collection will not accept insertion of documents where the index key or keys match an existing value in the index. Specify true to create a unique index. The default value is false.

sparse	: Boolean	If true, the index only references documents with the specified field. These indexes use less space but behave differently in some situations (particularly sorts). The default value is false.

db.system.indexes.find() # shows all indexes in current databse.
db.poeple.getIndexes() give detaila abuot the collection

db.people.dropIndexes() # drops the indexes

Unique indexes are the ones which will not allow multiple values to be set to the key.


*Agregation*

<<<<<<< HEAD
=======

Example:
Always in List []
db.products.aggregate([{$group:{
	"_id":"$manufacturer",
	"num_products":{"$sum":1}

}
}
])


Aggregate Pipeline : $project (select )-->$match  (filter)--> $group (aggregatopm) --> sort --> skip -->limit -->unwind

Compoung groupings:

db.products.aggregate([
	{$group:
		{
			"_id":
				{
					"maker":$manufacturer,
		   			"category":$category
		   		},
			"num_products":{$sum:1}
		}
	}
)]



Aggregate expressions:
sum , avg, min , max, push , addtoSet, first , last

*addtoSet # push is similar but it will not guarantee uniqueness
db.products.aggregate([
	{$group:
		{
			"_id":
				{
					"maker":$manufacturer,
		   			 
		   		},
			"categories":{$addtoSet:$category}
		}
	}
)]


*MAx
db.products.aggregate([
	{$group:
		{
			"_id":
				{
					"maker":"$manufacturer",
		   			 
		   		},
			"max_price":{$max:"$price"}
		}
	}
)]


$project :
allows to modify/reshape document like add or remove keys or use simple funcs like toUpper etc

db.products.aggregate([
	{$project:
		{
			_id:0,
			'maker':{toLower("$manufactuer")},
			'details':{ category: "$category", price:{$multiply:[$price,10]}},
			'item':'$name'
		}
	}
])
http://docs.mongodb.org/manual/reference/sql-aggregation-comparison/







Example:
Always in List []
db.products.aggregate([{$group:{
	"_id":"$manufacturer",
	"num_products":{"$sum":1}

}
}
])


Aggregate Pipeline : $project (select )-->$match  (filter)--> $group (aggregatopm) --> sort --> skip -->limit -->unwind

Compoung groupings:

db.products.aggregate([
	{$group:
		{
			"_id":
				{
					"maker":$manufacturer,
		   			"category":$category
		   		},
			"num_products":{$sum:1}
		}
	}
)]



Aggregate expressions:
sum , avg, min , max, push , addtoSet, first , last

*addtoSet # push is similar but it will not guarantee uniqueness
db.products.aggregate([
	{$group:
		{
			"_id":
				{
					"maker":$manufacturer,
		   			 
		   		},
			"categories":{$addtoSet:$category}
		}
	}
)]


*MAx
db.products.aggregate([
	{$group:
		{
			"_id":
				{
					"maker":"$manufacturer",
		   			 
		   		},
			"max_price":{$max:"$price"}
		}
	}
)]


$project :
allows to modify/reshape document like add or remove keys or use simple funcs like toUpper etc

db.products.aggregate([
	{$project:
		{
			_id:0,
			'maker':{toLower("$manufactuer")},
			'details':{ category: "$category", price:{$multiply:[$price,10]}},
			'item':'$name'
		}
	}
])
http://docs.mongodb.org/manual/reference/sql-aggregation-comparison/








=======
**APPLICATION ENGINEERING***

Replica Set:
How replication works in MongoDB
MongoDB achieves replication by the use of replica set. A replica set is a group of mongod instances that host the same data set. In a replica one node is primary node that receives all write operations. All other instances, secondaries, apply operations from the primary so that they have the same data set. Replica set can have only one primary node
At the time of automatic failover or maintenance, election establishes for primary and a new primary node is elected.
After the recovery of failed node, it again join the replica set and works as a secondary node.

Starting a replica set:
mongod --port "PORT" --dbpath "YOUR_DB_DATA_PATH" --replSet "REPLICA_SET_INSTANCE_NAME"
mongod --port 27017 --dbpath /data/rs1 --replSet rs1 --fork
mongod --port 27018 --dbpath /data/rs2 --replSet rs1 --fork
mongod --port 27019 --dbpath /data/rs3 --replSet rs1 --fork


Within the mongo shell:

config = { _id : rs1,members = [{
		{_id:0, host:"localhost:27017", priority=0,slaveDelay=5},
		{_id:1, host:"localhost:27018"},
		{_id:2, host:"localhost:27019"}
}]}

rs.initiate()
rs.status()


rs.slaveOK() is the command which will allow us to read from secondary on the connection that this command is run on.

It will start a mongod instance with the name rs0, on port 27017. Now start the command prompt and connect to this mongod instance. In mongo client issue the command rs.initiate() to initiate a new replica set. To check the replica set configuration issue the command rs.conf(). To check the status of replica sete issue the command rs.status().
Basic syntax of rs.add() command is as follows:
>rs.add(HOST_NAME:PORT)


pymongo will allow us to directly connect to the replica set.

conn = Mongoclient(host='mongodb://localhost:27017',replicaSet=rs1,w=1,j=True)
db = conn.test
things = db.things

things.insert({...}) # this will write it to primary


MongoReplicaSetClient can be used to connect to replica set 


*DUMPING and RESTORING*
mongodump --host HOST_NAME --port PORT_NUMBER	This commmand will backup all databases of specified mongod instance.	mongodump --host tutorialspoint.com --port 27017
mongodump --dbpath DB_PATH --out BACKUP_DIRECTORY		mongodump --dbpath /data/db/ --out /data/backup/
mongodump --collection COLLECTION --db DB_NAME	This command will backup only specified collection of specified database.	mongodump --collection mycol --db test

Basic syntax of mongorestore command is
mongorestore

Stats:
mongostat
This command checks the status of all running mongod instances and return counters of database operations. These counters include inserts, queries, updates, deletes, and cursors. Command also shows when you’re hitting page faults, and showcase your lock percentage.This means that you're running low on memory, hitting write capacity or have some performance issue.

mongotop
This command track and report the read and write activity of MongoDB instance on a collection basis. By default mongotop returns information in each second, by you can change it accordingly. You should check that this read and write activity matches your application intention, and you’re not firing too many writes to the database at a time, reading too frequently from disk, or are exceeding your working set size


*Relationships*
*Modeling Embedded Relationships*
In the embedded approach, we will embed the address document inside the user document.

{
   "_id":ObjectId("52ffc33cd85242f436000001"),
   "contact": "987654321",
   "dob": "01-01-1991",
   "name": "Tom Benzamin",
   "address": [
      {
         "building": "22 A, Indiana Apt",
         "pincode": 123456,
         "city": "Los Angeles",
         "state": "California"
      },
      {
         "building": "170 A, Acropolis Apt",
         "pincode": 456789,
         "city": "Chicago",
         "state": "Illinois"
      }]
} 
db.users.findOne({"name":"Tom Benzamin"},{"address":1}) # THis gives the address


*Modeling Referenced Relationships*
{
   "_id":ObjectId("52ffc33cd85242f436000001"),
   "contact": "987654321",
   "dob": "01-01-1991",
   "name": "Tom Benzamin",
   "address_ids": [
      ObjectId("52ffc4a5d85242602e000000"),
      ObjectId("52ffc4a5d85242602e000001")
   ]
}
var result = db.users.findOne({"name":"Tom Benzamin"},{"address_ids":1})
var addresses = db.address.find({"_id":{"$in":result["address_ids"]}})



* What is a Covered Query
As per the official MongoDB documentation, a covered query is a query in which:
    all the fields in the query are part of an index and
    all the fields returned in th query are in the same index
Since all the fields present in the query are part of an index, MongoDB matches the query conditions and returns the result using the same index without actually looking inside documents

*Explain
>db.users.find({gender:"M"},{user_name:1,_id:0}).explain()
 The true value of indexOnly indicates that this query has used indexing.
The cursor field specifies the type of cursor used. BTreeCursor type indicates that an index was used and also gives the name of the index used. BasicCursor indicates that a full scan was made without using any indexes.
n indicates the number of documents matching returned.
nscannedObjects indicates the total number of documents scanned
nscanned indicates the total number of documents or index entries scanned 
*hint
The $hint operator forces the query optimizer to use the specified index to run a query. This is particularly useful when you want to test performance of a query with different indexes. For example, the following query specifies the index on fields gender and user_name to be used for this query :
>db.users.find({gender:"M"},{user_name:1,_id:0}).hint({gender:1,user_name:1})

*MongoDB does not support multi-document atomic transactions. However, it does provide atomic operations on a single document. So if a document has hundred fields the update statement will either update all the fields or none, hence maintaining atomicity at document-level. 


*Searching:
 Now that we have created the text index on post_text field, we will search for all the posts that have word tutorialspoint in their text.

>db.posts.find({$text:{$search:"tutorialspoint"}})

The above command returned the following result documents having tutorialspoint word in thier post text:

{ 
   "_id" : ObjectId("53493d14d852429c10000002"), 
   "post_text" : "enjoy the mongodb articles on tutorialspoint", 
   "tags" : [ "mongodb", "tutorialspoint" ]
}
{
   "_id" : ObjectId("53493d1fd852429c10000003"), 
   "post_text" : "writing tutorials on mongodb",
   "tags" : [ "mongodb", "tutorial" ] 
}


*GridFS is the MongoDB specification for storing and retrieving large files such as images, audio files, video files, etc. It is kind of a file system to store files but its data is stored within MongoDB collections. GridFS has the capability to store files even greater than its document size limit of 16MB. 


*Sharding:
Data Partitioning

MongoDB distributes data, or shards, at the collection level. Sharding partitions a collection’s data by the shard key


Write concern:
w = 1 , j= 0 means wait for ack from mongo that it received the request frmo app
w = 1 , j = 1 means wait for ack after the changes are written to the journal log.
w = 0 , j = 0 , just fire and forget which is the default behaviour.

w = 'majority' can be used as well which means wait for write ack from majority of the nodes.