
*struct
The struct module includes functions for converting between strings of bytes and native Python data types such asnumbers and strings.
v=5 ; import struct ; s = struct.Struct('I') #Argument should be format specifier
v2=s.pack(v) # converts into binary
s.unpack(v2) # converts into relevant data type

*shelve
The shelve module can be used as a simple persistent storage option for Python objects when a relational database
is overkillused to internally pickle objects in key value pair .
import shelve
s = shelve.open('test.db')
s['k1'] = range(10)
s.close()
Shelves do not track modifications to volatile objects, by default.To automatically catch changes to volatile objects stored in the shelf, open the shelf with writeback enabled. The
writeback flag causes the shelf to remember all of the objects retrieved from the database using an in-memory cache.
Each cache object is also written back to the database when the shelf is closed.

*pickle/cPickle
pickle module implements an algorithm for turning an arbitrary Python object into a series of bytes. This
process is also called serializing” the object.Once the data is serialized, you can write it to a file, socket, pipe, etc.
In [3]: d
Out[3]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
In [5]: p = pickle.dumps(d)
In [6]: p
Out[6]: '(lp0\nI0\naI1\naI2\naI3\naI4\naI5\naI6\naI7\naI8\naI9\na.'
n [7]: f = pickle.loads(p)
In [8]: f
Out[8]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
OR

f = open('tmp.file','wb+')
pickle.sump(d,f)
f.close()

When working with your own classes, you must ensure that the class being pickled appears in the namespace of the
process reading the pickle. Only the data for the instance is pickled, not the class definition. The class name is used to
find the constructor to create the new object when unpickling




*For large amounts of data, it may be more efficient(coz stored contiguous blocks of memory) to use an array instead of a list, ex: import array ; a = array.array('i',range(10)) #i is code representing integer
Only difference between list and array is array hols only same data type
a.tofile(output.file)    # to read and write directly from array 
a.fromfile(output.file)


*heapq and bisect are used to generate lists in sorted order when the list is changing continuously
In [88]: for i in range(1,20):
    r = random.randint(1,100)
    bisect.insort(l,r) # this inserts the randm number in sorted order.

*list is not thread safe hence use Queue for queue operations even though list can easily simulate a Queue with insert and remove. multiprocessing.Queue even has a version to work with multiple processes.
 Queue.LifoQueue is the stack implementation.
Queue provides   q.task_done() method supposed to be called after get to notify other threads that processing is done for last get.

**Collections : Deque, namedtuple,ordereddict,defaultdict,Counter
*Deque is a double ended  queue with methods like pop,popleft,append,appendleft,extend,extendleft , rotate,rotateleft. Important application undo/redo functionality in applications.
*defaultdict is used to assign and add key value pairs into dict when accessed and key not present in the dict. for ex: d = defaultdict(int); d = {'s1':1} ; accessing d['s2'] adds 0 as value in the dict. We can even have custom methods just like int is being used here.
*A Counter is a container that keeps track of how many times equivalent values are added. 
c = collections.Counter('extremely')
In [4]: c
Out[4]: Counter({'e': 3, 'm': 1, 'l': 1, 'r': 1, 't': 1, 'y': 1, 'x': 1})
*An OrderedDict is a dictionary subclass that remembers the order in which its contents are added.
*namedtuple instances are just as memory efficient as regular tuples because they  do not have per-instance dictionaries. 
In [5]: p = collections.namedtuple('p','name age')
In [6]: p1 = p('simon',30)


*os.path can be used to split dir and file names file extensions expand env variables, normalise paths, get create modifytime 
os.stat give stats like permission etc abt the file

*The fileinput module is a framework for creating command line programs for processing text files in a filter-ish manner, no need to worry at opening file reading line by line and related error handling. Pg.268 , fileinput.input()

*linecache can be used to extract specific lines from files , it even uses its own cache for efficient retirieval of content . linecache.getline('sim.txt', 5)

*The tempfile module provides several functions for creating filesystem resources  ecurely. TemporaryFile() opens and returns an un-named file,  NamedTemporaryFile()  , t1 = tempfile.NamedTemporaryFile()

*shutil.copyfile , copyfileobject, copy , copy2 used to make a copy of the file. 
move to move file 
copystat copies all stats from f1 to f2 , copymode copies permission.
copytree , rmtree - recursive directory operations

*dircache provided listdir method to list the contents of directory , it also caches the entries for next time use. if the timstamp in dir changes only then it updates the cache.

***Pg.11 - Types of Exceptions  and Warning *** Must Read ***

Unicode ; https://docs.python.org/2/howto/unicode.html
Theory:
'''
BOM = Byte order mark
255254 at the beginning means little endian
254255 means big endian
UTF-8 can go upto 8 bytes . If the 1st bit is 0 then its a 1 byte character.The 1st  byte is called leading byte and subsequent bytes called continuation bytes. Leading byte gives the info on how many continuation bytes  needs to be read. For example if 1st byte has 110XXXXX 10XXXXXX then the number of 1's in 1st byte show the number of bytes ie 2.
Unicode != UTF-8 , Unicode is mapping from symbol to codepoint. UTF-8 is the binary representation of the codepoint.
So when u want to convert from bytes to codepoints we decode the stream and when we need to convert from codepoints to bytes we encode them.
Any bytesstring be it file or network stream needs to be decoded into Unicode before playing with the data in your program and for this u need to know the encoding of the data that is coming in. And similarly when u want to send the data out to network or file or databse make sure  u encode the data into utf-8 before saving
Decode as early as possible , Unicode everywhere in your program with 'u' and encode into Bytes as late as possible'''

Fact of Life #1 : Computers are built on  only bytes , Files, Networks everything
In python str: sequence of bytes (2.x default)
unicode : sequence on code points (3.x default)
unicode.encode --> bytes
bytes.decode -->unicode

Python implicitly converts str to unicode during operations lije below
s="Hello" + u"World"
s=u"Hello World" , it does so by "World".decode('ascii')
The above implicit conversin causes issues most of the times.

One-character Unicode strings can also be created with the unichr()
built-in function, which takes integers and returns a Unicode string of length 1
that contains the corresponding code point.  The reverse operation is the
built-in ord() function that takes a one-character Unicode string and
returns the code point value
In [62]: unichr(1234)
Out[62]: u'\u04d2'
In [63]: ord(u'\u04d2')
Out[63]: 1234
*\x takes 2 hex digits , \u 4 and \U 8 

*library python-ftfy fixes mojibake o garbage mis encoded text for u 
*decode translates str to unicode instance, encode  does vice versa. str uses 8 bytes to represet a char where as for unicode it can differ from 8 to 32.
**In general, all text data needs to be decoded from its byte representation as it is read, and encoded from the internal values to a specific representation as it is written. codecs module  provides classes that manage the data encoding and decoding for you,
** codecs.open automatically manages this conversion.

Only when a tty is associated with sys.stdout default encoding is set, if there is no terminal asociated its assumed that encoding will be set manually.
So if not done then pipe's will fail with unicode exception when used as output.
To overcome we have to assign getwriter to sys.stdout as shown below
sys.stdout = codecs.get_writer(encoding)(sys.stdout)
You can get the default locale by using below
lang, encoding = locale.getdefaultlocale()
Same needs to be done for sys.stdin when input is not coming from console or if it is coming from a pipe.

codecs.EncodedFile() can be used to read and write to files if the data encoding is different and the file needs to be written in different encoding.
encoded_file = codecs.EncodedFile(buffer, data_encoding=’utf-8’,
file_encoding=’utf-16’)

# Set standard output encoding to UTF-8.
sys.stdout = codecs.getwriter(’UTF-8’)(sys.stdout) #needed when printing text outside asci

*difflib module used to compare sequences and find differences , output more or less similar to Unix diff command.
import difflib ; d = difflib.ndiff(text1,text2)
get close match works like spell checker google search
In [114]: difflib.get_close_matches('prit',keyword.kwlist)
Out[114]: ['print']


*import string ; string.ascii , string.digits etc have a lot of constants which can be used instead of manually declaring.
string.capwords capitalises all words in a sentence.
string.translate can be used for translations 
import string;leet = string.maketrans(’abegiloprstz’, ’463611092572’) s = ’The quick brown fox jumped over the lazy dog.’
print s.translate(leet)
string.Template can be used to for text substituin in static files like xml , u can inherit this class even and specify your own delimiter etc.
t = string.Template("template cntent $var")
d = {'var':'value'}
t.safe_substitute(d) #This will replace var with value in template.

*StringIO and cStringIO – Work with text buffers using file-like API
This module implements an in-memory file object. This object can be used as input or output to most functions that expect a standard file object.
The StringIO class implements memory file versions of all methods available for built-in file objects, plus a getvalue method that returns the internal string value


*Regular Expressions
m = re.search(pattern,string) -- This returns the match object with m.string having string and m.re.pattern havgin matched pattern .
pattern mentioned above can be compiled as well before hand which reduces runtime overhead
ex: regex = re.compile(pattern ; m = regex.search(string))
By pre-compiling any expressions your module uses when the module is loaded you shift the compilation work to application startup time, instead of a point where the program is responding to a user action.
re.findall(pattern,string) finds all patterns and returns a string of pattern matched , finditerreturns match object smilarly
non greedy match means the matching stops as soon as the match is found , it does not go on to scan the whole string .
match.groups, match.group can be used to fetch specific groups that have matched
compile function has options like re.IGNORECASE, re.MULTILINE ,re.UNICODE
Regular expression testing tool mentioned on page 89 -- Very useful

*textwrap.fill and textwrap.dedent used for wrapping and unindenting 

*datetime:
import time ; time.ctime => onvert a time in seconds since the Epoch to a string in local time
In [116]: time.time()
Out[116]: 1407483165.089312
In [117]: time.ctime(time.time())
Out[117]: 'Fri Aug  8 13:02:51 2014'

print datetime.datetime.now().ctime() #Gives current time and converts into ctime
Setting date : datetime.date(2008, 3, 12)
Setting time : datetime.time(1, 3, 12)
You can use datetime to perform basic arithmetic on date values via the timedelta clas
today = datetime.date.today()
one_day = datetime.timedelta(days=1)
yesterday = today - one_day
print ’Yesterday:’, yesterday
Normal comparison operators >,< can be used to comparre date and time objects
datetime.datetime.now().time() or .day or .date or .second etc gives current values
You can even change the format in whic daatimetime is reported 
format = "%a %b %d %H:%M:%S %Y"
today = datetime.datetime.today()
print ’strptime:’, today.strftime(format)

*dateutil is an excellent 3rd party module which extends datetime and provides easy to use relateiv api's

*DBM style databases are databses with key value pair sorga only.

*SQLITE3
1.) Create a db file using connect function if it doestn exist
with sqlite3.connect('sqllte.db') as conn;
    conn.executescript(script_content_read_into_file)
    conn.execute(insert into project (name, description, deadline)
    values (’pymotw’, ’Python Module of the Week’, ’2010-11-01’))
2.)Querying is a two step process. First, run the query with the cursor’s execute() method to tell the database engine
what data to collect. Then, use fetchall() to retrieve the results. The return value is a sequence of tuples containing
the values for the columns included in the select clause of the query
cur  = conn.cursor() ; cur.execute('select * from task') ; for r in cur.fetchall():print r - THis will return tuples with data values
To get column info - > for colinfo in cursor.description: print colinfo

Connection objects have a row_factory property that allows the calling code to control the type of object created to represent each row in the query result set.  Row instances can be accessed by column index and name, example below:
cur = conn.cursor(); cur.row_factory= sqlite.Row ; 
cur.execute('select * from task'); for r in cur.fetchall(): print r['id'], r['name'] # u see the references are being made by column names

Use variables to prevent SQL injection attacks : ecample for named variables/
query = "select * from task where id = :id"
cur.execute(query,{'id':123}) or u can use a variable as well for 123 which is declared in advance.
Query parameters can be used with select, insert, and update statements. They can appear in any part of the query where a literal value is legal.
To apply the same SQL instruction to a lot of data use executemany(). This is useful for loading data, since it avoids looping over the inputs in Python and lets the underlying library apply loop optimizations.Example below:
SQL = "insert into task (details, priority, status, deadline, project) values (:details, :priority, 'active', :deadline, :project)"
d = csv.DictReader(open('sam.csv'))
cur.executemany(SQl,d)
d looks somehitng like below:
In [38]: for i in d:
    print i
{'project': 'pymotw', 'priority': '2', 'deadline': '2010-10-02', 'details': 'finish reviewing markup'}
{'project': 'pymotw', 'priority': '2', 'deadline': '2010-10-03', 'details': 'revise chapter intros'}
{'project': 'pymotw', 'priority': '1', 'deadline': '2010-10-03', 'details': 'subtitle'}

*Conversion for types beyond those supported by default is enabled in the database connection using the detect_types flag. Use PARSE_DECLTYPES is the column was declared using the desired type when the table was defined.
with sqlite3.connect(db_filename, detect_types=sqlite3.PARSE_DECLTYPES) as conn:
To open an in-memory database, use the string ’:memory:’ instead of a filename when creating the Connection.
with sqlite3.connect(’:memory:’) as conn: 

